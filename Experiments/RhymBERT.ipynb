{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers\n",
        "! pip install -q wandb"
      ],
      "metadata": {
        "id": "RwBbaKdEXRsi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_4sTTq9XALJ",
        "outputId": "a15008a8-a4ed-4efa-dd16-a4ec26870e12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mam2502\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "\n",
        "import torch\n",
        "from transformers import (AutoModelForMaskedLM, BertTokenizerFast, get_linear_schedule_with_warmup)\n",
        "\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from torch.utils.data import (Dataset, \n",
        "                              random_split,\n",
        "                              DataLoader,\n",
        "                              RandomSampler,\n",
        "                              SequentialSampler)\n",
        "\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import subprocess\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "wandb.login(key=\"140ee313fa4d9145f53618b86356098fa858e670\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as path\n",
        "\n",
        "if not path.exists(\"/content/drive\"):\n",
        "  !sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "  !sudo apt-get update -qq 2>&1 > /dev/null\n",
        "  !sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
        "  !google-drive-ocamlfuse\n",
        "\n",
        "  !sudo apt-get install -qq w3m # to act as web browser \n",
        "  !xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
        "  %cd /content\n",
        "  !mkdir drive\n",
        "  %cd drive\n",
        "  !mkdir MyDrive\n",
        "  %cd ..\n",
        "  %cd ..\n",
        "  !google-drive-ocamlfuse /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "20wMBoPlSw01"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_to_project_folder = \"\"\n",
        "\n",
        "if not os.path.isdir(\"./Project\"):\n",
        "    env = os.environ.copy()\n",
        "    subprocess.run(\n",
        "        'ln -s \"/content/drive/MyDrive/Project\" /content/Project',\n",
        "        shell=True,\n",
        "        env=env,\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "lCX71sN0Xetc",
        "outputId": "da908d53-5d36-4836-83e1-ca924fcb2b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7d55013c229d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpath_to_project_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;34m\"\"\"Internal helper to mount Google Drive.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/var/colab/mp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is unsupported in this environment.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: google.colab.drive is unsupported in this environment."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_project_folder = \"\"\n",
        "config = {\n",
        "    \"path_to_data_folder\": '/content/Project/data/',\n",
        "    'random_seed': 73,\n",
        "    'batch_size': 64,\n",
        "    'max_len': 64,\n",
        "    'limerick_file_name': 'limericks_ballas_oedilf_clean.csv',\n",
        "    'model_name': 'bert-base-uncased',\n",
        "    'training_storage_path': '/content/drive/MyDrive/',\n",
        "    'total_epochs': 4,\n",
        "    'learning_rate': 2e-5,\n",
        "    'iteration_step_to_log_checkpoint': 1,\n",
        "    'warmup_steps': 300\n",
        "}"
      ],
      "metadata": {
        "id": "6TIZt1rYX11g"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limerick_df = pd.read_csv(os.path.join(config['path_to_data_folder'], config['limerick_file_name']))\n",
        "limerick_df = limerick_df.fillna('')\n",
        "len(limerick_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK7WtnJBZqXk",
        "outputId": "693a9b26-3ded-4b4b-ebf0-92e821cbcdbf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "153797"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "limerick_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "9Vc416EZV1dN",
        "outputId": "6f27b10c-9b2d-4d01-df2c-7bb562fdcf24"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-570de178-f613-4589-9931-53490fd0957b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>limericks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>capn jack was washed over the side\\nhis crew s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>as a soup bisque is best when served hot\\nmade...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>simply add to the grasp of a rhesus\\nthe antit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abeds where you sleep in the night\\nunless you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a smiling young fellow from spain\\nfell asleep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153792</th>\n",
              "      <td>esps remove dust from a flue\\nthough hightech ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153793</th>\n",
              "      <td>as a gent of the uppermost class\\nim deserving...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153794</th>\n",
              "      <td>breaking free the crook busted the link\\nof th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153795</th>\n",
              "      <td>mr owl ate ms nans metal worm \\ntragic fable t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153796</th>\n",
              "      <td>the false positive rate of a test\\ncrucial fac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>153797 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-570de178-f613-4589-9931-53490fd0957b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-570de178-f613-4589-9931-53490fd0957b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-570de178-f613-4589-9931-53490fd0957b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                limericks\n",
              "0       capn jack was washed over the side\\nhis crew s...\n",
              "1       as a soup bisque is best when served hot\\nmade...\n",
              "2       simply add to the grasp of a rhesus\\nthe antit...\n",
              "3       abeds where you sleep in the night\\nunless you...\n",
              "4       a smiling young fellow from spain\\nfell asleep...\n",
              "...                                                   ...\n",
              "153792  esps remove dust from a flue\\nthough hightech ...\n",
              "153793  as a gent of the uppermost class\\nim deserving...\n",
              "153794  breaking free the crook busted the link\\nof th...\n",
              "153795  mr owl ate ms nans metal worm \\ntragic fable t...\n",
              "153796  the false positive rate of a test\\ncrucial fac...\n",
              "\n",
              "[153797 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(config['model_name'])\n",
        "print(tokenizer.vocab_size)\n",
        "tokenizer.model_max_length = config['max_len']\n",
        "tokenizer.add_tokens('[EOL]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYuiqEMJZsLh",
        "outputId": "16306c9b-3f5c-4f41-f612-6866fd2c4465"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30522\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_ids('[EOL]'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsaWAyoO6elv",
        "outputId": "214286b4-576a-46fa-d175-f5d481f53c9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LimerickDataset(Dataset):\n",
        "    def __init__(self, data, max_length=config['max_len']):\n",
        "        self.input_ids = []\n",
        "        self.original_input_ids = []\n",
        "        self.attn_masks = []\n",
        "        self.labels = []\n",
        "        indices_of_last_words = []\n",
        "        \n",
        "        for limerick in tqdm(data):\n",
        "            encodings_dict = tokenizer(limerick.replace('\\n', ' [EOL] '),\n",
        "                                     truncation=True,\n",
        "                                     max_length=max_length,\n",
        "                                     padding='max_length'\n",
        "                                     )\n",
        "            self.original_input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            new_input_ids = []\n",
        "            labels = []\n",
        "            last_word_id = -1\n",
        "            word_id_repetition_count = 0\n",
        "            count = 0\n",
        "            for i, word_id in enumerate(encodings_dict.word_ids()):\n",
        "                if encodings_dict.input_ids[i] == 30522:\n",
        "                    while word_id_repetition_count != 0:\n",
        "                        # print(tokenizer.decode(encodings_dict.input_ids[i]), word_id)\n",
        "                        word_id_repetition_count -= 1\n",
        "                        labels.pop()\n",
        "                        labels.insert(-1, new_input_ids.pop())\n",
        "                        count += 1\n",
        "                    [new_input_ids.append(103) for j in range(count)]\n",
        "                    count = 0\n",
        "                    new_input_ids.append(30522)\n",
        "                    labels.append(-100)\n",
        "                else:\n",
        "                    if last_word_id == word_id:\n",
        "                        word_id_repetition_count += 1\n",
        "                    else:\n",
        "                        word_id_repetition_count = 1\n",
        "                    last_word_id = word_id\n",
        "                    new_input_ids.append(encodings_dict.input_ids[i])\n",
        "                    labels.append(-100)\n",
        "            \n",
        "\n",
        "            self.input_ids.append(torch.tensor(new_input_ids))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "            self.labels.append(torch.tensor(labels))\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx], self.labels[idx], self.original_input_ids[idx]"
      ],
      "metadata": {
        "id": "061GeUQxYrq-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limerick_dataset = LimerickDataset(limerick_df['limericks'].values, max_length=config['max_len'])\n",
        "\n",
        "limerick_dataloader = DataLoader(limerick_dataset, sampler=RandomSampler(limerick_dataset), batch_size=config['batch_size'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyeB_oSjbEke",
        "outputId": "aea42610-b1b3-4274-a2d9-4d630f173afa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 153797/153797 [00:58<00:00, 2622.77it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "model = AutoModelForMaskedLM.from_pretrained(config['model_name'])\n",
        "model.max_seq_len = config['max_len']\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=config['learning_rate'])\n",
        "model = model.to(device)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=config['warmup_steps'],\n",
        "                                            num_training_steps=len(limerick_dataloader) * config['total_epochs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SeEmKTB2hcM",
        "outputId": "2fc2d8f5-ee3e-4f56-b049-f42c6bf41efe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(\n",
        "    name = \"RhymeBERT_2\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
        "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"poetai-project\" ### Project should be created in your wandb account\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "13w7TrvR22X9",
        "outputId": "7e793736-b6ad-4668-bce1-5a6a6118479b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "wandb version 0.13.6 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221208_104251-2keu3b1j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/am2502/poetai-project/runs/2keu3b1j\" target=\"_blank\">RhymeBERT_2</a></strong> to <a href=\"https://wandb.ai/am2502/poetai-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def log_checkpoint(iteration, model, optimizer, metric=None):\n",
        "    if iteration % config['iteration_step_to_log_checkpoint'] == 0 or iteration == config['total_iterations']:\n",
        "        state = {\n",
        "            'iteration': iteration + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict()\n",
        "        }\n",
        "        check_point_dir = config['training_storage_path']\n",
        "\n",
        "        if not os.path.exists(check_point_dir):\n",
        "            os.makedirs(check_point_dir)\n",
        "\n",
        "        if metric == None:\n",
        "            checkpoint_file_path = check_point_dir + f\"/poet_ai_checkpoint_rhymebert_\"+str(iteration)+\".h5\"\n",
        "            torch.save(state, checkpoint_file_path)\n",
        "        else:\n",
        "            # considering minimization effort\n",
        "            onlyfile_metrics = [float(f.split(\"_checkpoint.h5\")[0]) for f in listdir(check_point_dir) if isfile(join(check_point_dir, f)) and \"_checkpoint.h5\" in f]\n",
        "\n",
        "            if len(onlyfile_metrics) > 0 and metric < sorted(onlyfile_metrics)[0]:\n",
        "                checkpoint_file_path = check_point_dir + f\"/{metric}_checkpoint.h5\"\n",
        "                torch.save(state, checkpoint_file_path)\n",
        "                os.remove(check_point_dir + f\"/{sorted(onlyfile_metrics)[0]}_checkpoint.h5\")"
      ],
      "metadata": {
        "id": "IJkm9z2I25wB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    batch_bar = tqdm(total=len(limerick_dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(limerick_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "        outputs = model(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask=b_masks)\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        batch_bar.set_postfix(\n",
        "            step=\"{:d}\".format(step),\n",
        "            loss=\"{:.04f}\".format(loss.item()))\n",
        "        batch_bar.update()\n",
        "\n",
        "        wandb.log({\"train_loss\": loss.item(),'train_epochs': epoch})\n",
        "    log_checkpoint(epoch, model, optimizer)\n",
        "    return total_train_loss / len(limerick_dataloader)"
      ],
      "metadata": {
        "id": "xPT1f16c3bzz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_checkpoint(epoch, model, optimizer)"
      ],
      "metadata": {
        "id": "-Yy3T6egWh7-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(config['total_epochs']):\n",
        "    print(f'Epoch {epoch} of', config['total_epochs'])\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3o1O6D6bE8n",
        "outputId": "3bea1e06-642a-43c8-ce00-dc7514214ffc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 of 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 of 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 of 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 of 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_ids, mask, labels, orig) in enumerate(limerick_dataloader):\n",
        "    print(labels[2])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02W_a-GIppS0",
        "outputId": "9ceb7029-6a24-4e9a-9463-97c6b3a50d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  1054,\n",
            "        15689,  -100,  -100,  -100,  -100,  -100, 18224,  4939,  -100,  -100,\n",
            "        11302,  -100,  -100,  -100,  -100,  8065,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  3424, 25078,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "metadata": {
        "id": "atHbL08otD9Z"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}